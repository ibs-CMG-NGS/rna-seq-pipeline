#!/usr/bin/env python3
"""
FastQC ê²°ê³¼ ìë™ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

FastQC ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ê³  FASTQC_GUIDE.mdì— ëª…ì‹œëœ ê¸°ì¤€ì— ë”°ë¼
ê° ìƒ˜í”Œì˜ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

RNA-seq íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ì •ìƒì ì¸ FAIL íŒ¨í„´ì„ í—ˆìš©í•˜ê³ ,
ì‹¤ì œ ë¬¸ì œê°€ ìˆëŠ” ìƒ˜í”Œë§Œ í”Œë˜ê·¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import re
import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple
from collections import defaultdict


class FastQCEvaluator:
    """FastQC ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # RNA-seqì—ì„œ ì •ìƒì ìœ¼ë¡œ FAILì´ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ëª¨ë“ˆë“¤
    RNA_SEQ_ACCEPTABLE_FAILS = {
        'Per base sequence content',
        'Sequence Duplication Levels',
        'Overrepresented sequences',
        'Adapter Content'  # trimming ì „ì—ë§Œ
    }
    
    def __init__(self, config: Dict):
        """
        Args:
            config: QC í‰ê°€ ê¸°ì¤€ì„ ë‹´ì€ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.config = config
        self.results = []
        
    def parse_fastqc_data(self, fastqc_data_path: str) -> Dict:
        """
        FastQCì˜ fastqc_data.txt íŒŒì¼ì„ íŒŒì‹±
        
        Args:
            fastqc_data_path: fastqc_data.txt íŒŒì¼ ê²½ë¡œ
            
        Returns:
            íŒŒì‹±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        data = {
            'basic_stats': {},
            'per_base_quality': [],
            'per_sequence_quality': [],
            'per_base_n_content': [],
            'sequence_length': [],
            'adapter_content': [],
            'modules': {}
        }
        
        current_module = None
        in_data_section = False
        
        with open(fastqc_data_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                
                if line.startswith('>>') and not line.startswith('>>END_MODULE'):
                    # ìƒˆë¡œìš´ ëª¨ë“ˆ ì‹œì‘
                    parts = line[2:].split('\t')
                    module_name = parts[0]
                    module_status = parts[1] if len(parts) > 1 else 'unknown'
                    current_module = module_name
                    data['modules'][module_name] = module_status
                    in_data_section = True
                    continue
                    
                if line.startswith('>>END_MODULE'):
                    current_module = None
                    in_data_section = False
                    continue
                
                if line.startswith('#') or not line:
                    continue
                
                if not in_data_section:
                    continue
                
                # ê° ëª¨ë“ˆë³„ ë°ì´í„° íŒŒì‹±
                if current_module == 'Basic Statistics':
                    parts = line.split('\t')
                    if len(parts) >= 2:
                        data['basic_stats'][parts[0]] = parts[1]
                        
                elif current_module == 'Per base sequence quality':
                    parts = line.split('\t')
                    if len(parts) >= 7:
                        data['per_base_quality'].append({
                            'base': parts[0],
                            'mean': float(parts[1]),
                            'median': float(parts[2]),
                            'lower_quartile': float(parts[3]),
                            'upper_quartile': float(parts[4]),
                            'percentile_10': float(parts[5]),
                            'percentile_90': float(parts[6])
                        })
                        
                elif current_module == 'Per sequence quality scores':
                    parts = line.split('\t')
                    if len(parts) >= 2:
                        data['per_sequence_quality'].append({
                            'quality': int(parts[0]),
                            'count': float(parts[1])
                        })
                        
                elif current_module == 'Per base N content':
                    parts = line.split('\t')
                    if len(parts) >= 2:
                        data['per_base_n_content'].append({
                            'base': parts[0],
                            'n_count': float(parts[1])
                        })
                        
                elif current_module == 'Adapter Content':
                    parts = line.split('\t')
                    if len(parts) >= 2:
                        # ëª¨ë“  ì–´ëŒ‘í„° ì»¬ëŸ¼ì˜ ìµœëŒ€ê°’ ì¶”ì¶œ
                        max_adapter = max([float(x) for x in parts[1:] if x])
                        data['adapter_content'].append({
                            'position': parts[0],
                            'max_percentage': max_adapter
                        })
        
        return data
    
    def evaluate_sample(self, sample_name: str, fastqc_zip_path: str, 
                       is_trimmed: bool = False) -> Dict:
        """
        ê°œë³„ ìƒ˜í”Œì˜ FastQC ê²°ê³¼ë¥¼ í‰ê°€
        
        Args:
            sample_name: ìƒ˜í”Œ ì´ë¦„
            fastqc_zip_path: FastQC zip íŒŒì¼ ê²½ë¡œ
            is_trimmed: trimming í›„ ë°ì´í„°ì¸ì§€ ì—¬ë¶€
            
        Returns:
            í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # zip íŒŒì¼ ì••ì¶• í•´ì œ ê²½ë¡œ ì°¾ê¸°
        zip_path = Path(fastqc_zip_path)
        data_dir = zip_path.parent / zip_path.stem
        fastqc_data_path = data_dir / 'fastqc_data.txt'
        
        if not fastqc_data_path.exists():
            return {
                'sample': sample_name,
                'status': 'ERROR',
                'message': f'fastqc_data.txt not found: {fastqc_data_path}',
                'issues': [],
                'warnings': []
            }
        
        # ë°ì´í„° íŒŒì‹±
        data = self.parse_fastqc_data(str(fastqc_data_path))
        
        # í‰ê°€ ìˆ˜í–‰
        issues = []
        warnings = []
        
        # 1. Basic Statistics í™•ì¸
        basic_issues = self._check_basic_stats(data['basic_stats'])
        issues.extend(basic_issues)
        
        # 2. Per base sequence quality í™•ì¸
        quality_result = self._check_per_base_quality(data['per_base_quality'])
        if quality_result['severity'] == 'critical':
            issues.append(quality_result['message'])
        elif quality_result['severity'] == 'warning':
            warnings.append(quality_result['message'])
        
        # 3. Per base N content í™•ì¸
        n_content_result = self._check_n_content(data['per_base_n_content'])
        if n_content_result['severity'] == 'critical':
            issues.append(n_content_result['message'])
        elif n_content_result['severity'] == 'warning':
            warnings.append(n_content_result['message'])
        
        # 4. Adapter Content í™•ì¸ (trimming í›„ë¼ë©´ í•„ìˆ˜)
        if is_trimmed:
            adapter_result = self._check_adapter_content(data['adapter_content'], is_trimmed)
            if adapter_result['severity'] == 'critical':
                issues.append(adapter_result['message'])
            elif adapter_result['severity'] == 'warning':
                warnings.append(adapter_result['message'])
        
        # 5. ëª¨ë“ˆ ìƒíƒœ í™•ì¸ (RNA-seq ì •ìƒ íŒ¨í„´ ì œì™¸)
        module_issues = self._check_modules(data['modules'], is_trimmed)
        warnings.extend(module_issues)
        
        # 6. Per sequence quality í™•ì¸
        seq_quality_result = self._check_per_sequence_quality(data['per_sequence_quality'])
        if seq_quality_result['severity'] == 'warning':
            warnings.append(seq_quality_result['message'])
        
        # ìµœì¢… íŒì •
        if issues:
            status = 'FAIL'
            recommendation = 'REVIEW REQUIRED - ì‹¬ê°í•œ ë¬¸ì œ ë°œê²¬. ì¬ì‹œí€€ì‹± ë˜ëŠ” ì œì™¸ ê³ ë ¤'
        elif warnings:
            status = 'WARN'
            recommendation = 'CHECK RECOMMENDED - ê²½ë¯¸í•œ ë¬¸ì œ ìˆìŒ. ë¦¬í¬íŠ¸ í™•ì¸ ê¶Œì¥'
        else:
            status = 'PASS'
            recommendation = 'GOOD - ë¶„ì„ ì‚¬ìš© ê°€ëŠ¥'
        
        return {
            'sample': sample_name,
            'status': status,
            'recommendation': recommendation,
            'basic_stats': data['basic_stats'],
            'issues': issues,
            'warnings': warnings,
            'modules': data['modules']
        }
    
    def _check_basic_stats(self, stats: Dict) -> List[str]:
        """ê¸°ë³¸ í†µê³„ í™•ì¸"""
        issues = []
        
        # Total Sequences í™•ì¸
        if 'Total Sequences' in stats:
            total_seq = int(stats['Total Sequences'].replace(',', ''))
            min_sequences = self.config.get('min_total_sequences', 1000000)
            
            if total_seq < min_sequences:
                issues.append(
                    f'Total Sequences too low: {total_seq:,} (minimum: {min_sequences:,})'
                )
        
        # GC content í™•ì¸
        if '%GC' in stats:
            gc_content = int(stats['%GC'])
            min_gc = self.config.get('min_gc_content', 30)
            max_gc = self.config.get('max_gc_content', 70)
            
            if gc_content < min_gc or gc_content > max_gc:
                issues.append(
                    f'GC content out of range: {gc_content}% (expected: {min_gc}-{max_gc}%)'
                )
        
        return issues
    
    def _check_per_base_quality(self, quality_data: List[Dict]) -> Dict:
        """ì—¼ê¸°ë³„ í’ˆì§ˆ ì ìˆ˜ í™•ì¸"""
        if not quality_data:
            return {'severity': 'ok', 'message': ''}
        
        min_median_quality = self.config.get('min_median_quality', 28)
        min_lower_quartile = self.config.get('min_lower_quartile', 20)
        
        critical_positions = []
        warning_positions = []
        
        for item in quality_data:
            position = item['base']
            median = item['median']
            lower_q = item['lower_quartile']
            
            if median < 20:
                critical_positions.append(f"{position} (Q{median:.1f})")
            elif median < min_median_quality:
                warning_positions.append(f"{position} (Q{median:.1f})")
            elif lower_q < 10:
                critical_positions.append(f"{position} (LQ{lower_q:.1f})")
        
        if critical_positions:
            return {
                'severity': 'critical',
                'message': f'Critical: Low quality at positions: {", ".join(critical_positions[:5])}'
            }
        elif warning_positions:
            return {
                'severity': 'warning',
                'message': f'Warning: Quality below Q{min_median_quality} at {len(warning_positions)} positions'
            }
        
        return {'severity': 'ok', 'message': ''}
    
    def _check_per_sequence_quality(self, quality_data: List[Dict]) -> Dict:
        """ì‹œí€€ìŠ¤ë³„ í’ˆì§ˆ ì ìˆ˜ ë¶„í¬ í™•ì¸"""
        if not quality_data:
            return {'severity': 'ok', 'message': ''}
        
        # ì „ì²´ ë¦¬ë“œ ìˆ˜ ê³„ì‚°
        total_reads = sum(item['count'] for item in quality_data)
        
        # Q30 ì´ìƒ ë¦¬ë“œ ë¹„ìœ¨ ê³„ì‚°
        high_quality_reads = sum(
            item['count'] for item in quality_data 
            if item['quality'] >= 30
        )
        
        q30_percentage = (high_quality_reads / total_reads * 100) if total_reads > 0 else 0
        min_q30_percentage = self.config.get('min_q30_percentage', 75)
        
        if q30_percentage < min_q30_percentage:
            return {
                'severity': 'warning',
                'message': f'Low Q30+ reads: {q30_percentage:.1f}% (expected: >{min_q30_percentage}%)'
            }
        
        return {'severity': 'ok', 'message': ''}
    
    def _check_n_content(self, n_content_data: List[Dict]) -> Dict:
        """N ì—¼ê¸° í•¨ëŸ‰ í™•ì¸"""
        if not n_content_data:
            return {'severity': 'ok', 'message': ''}
        
        max_n_content = self.config.get('max_n_content', 5.0)
        critical_n_content = self.config.get('critical_n_content', 10.0)
        
        max_n = max(item['n_count'] for item in n_content_data)
        
        if max_n > critical_n_content:
            return {
                'severity': 'critical',
                'message': f'Critical: High N content: {max_n:.1f}% (max allowed: {critical_n_content}%)'
            }
        elif max_n > max_n_content:
            return {
                'severity': 'warning',
                'message': f'Warning: N content: {max_n:.1f}% (recommended: <{max_n_content}%)'
            }
        
        return {'severity': 'ok', 'message': ''}
    
    def _check_adapter_content(self, adapter_data: List[Dict], is_trimmed: bool) -> Dict:
        """ì–´ëŒ‘í„° í•¨ëŸ‰ í™•ì¸"""
        if not adapter_data:
            return {'severity': 'ok', 'message': ''}
        
        max_adapter = max(item['max_percentage'] for item in adapter_data)
        
        if is_trimmed:
            # Trimming í›„ì—ëŠ” ì—„ê²©í•œ ê¸°ì¤€
            max_allowed = self.config.get('max_adapter_trimmed', 1.0)
            if max_adapter > max_allowed:
                return {
                    'severity': 'critical',
                    'message': f'Adapter content after trimming: {max_adapter:.2f}% (should be <{max_allowed}%)'
                }
        else:
            # Trimming ì „ì—ëŠ” ê²½ê³ ë§Œ
            warn_threshold = self.config.get('warn_adapter_raw', 10.0)
            if max_adapter > warn_threshold:
                return {
                    'severity': 'warning',
                    'message': f'Adapter content: {max_adapter:.2f}% - Trimming recommended'
                }
        
        return {'severity': 'ok', 'message': ''}
    
    def _check_modules(self, modules: Dict, is_trimmed: bool) -> List[str]:
        """
        ê° ëª¨ë“ˆì˜ PASS/WARN/FAIL ìƒíƒœ í™•ì¸
        RNA-seqì—ì„œ ì •ìƒì ì¸ FAILì€ ì œì™¸
        """
        warnings = []
        
        for module_name, status in modules.items():
            # RNA-seqì—ì„œ ì •ìƒì ìœ¼ë¡œ FAILì´ ë‚˜ëŠ” ëª¨ë“ˆì€ ê±´ë„ˆëœ€
            if module_name in self.RNA_SEQ_ACCEPTABLE_FAILS:
                # Adapter ContentëŠ” trimming í›„ì—ëŠ” ì²´í¬í•´ì•¼ í•¨
                if module_name == 'Adapter Content' and is_trimmed:
                    if status == 'fail':
                        warnings.append(
                            f'Module FAIL: {module_name} (should pass after trimming)'
                        )
                continue
            
            # ë‚˜ë¨¸ì§€ ëª¨ë“ˆì—ì„œ FAILì€ ê²½ê³ 
            if status == 'fail':
                # Per tile sequence qualityëŠ” í”í•˜ë¯€ë¡œ ê²½ê³ ë§Œ
                if module_name == 'Per tile sequence quality':
                    continue  # ë¬´ì‹œ
                else:
                    warnings.append(f'Module FAIL: {module_name}')
        
        return warnings


def generate_summary_report(results: List[Dict], output_path: str):
    """
    ëª¨ë“  ìƒ˜í”Œì˜ í‰ê°€ ê²°ê³¼ë¥¼ ìš”ì•½í•œ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        results: ê° ìƒ˜í”Œì˜ í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    # ìƒíƒœë³„ ìƒ˜í”Œ ë¶„ë¥˜
    status_groups = defaultdict(list)
    for result in results:
        status_groups[result['status']].append(result)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("# FastQC ìë™ í‰ê°€ ë¦¬í¬íŠ¸\n\n")
        f.write("=" * 80 + "\n\n")
        
        # ìš”ì•½
        f.write("## ğŸ“Š ìš”ì•½\n\n")
        f.write(f"- ì´ ìƒ˜í”Œ ìˆ˜: {len(results)}\n")
        f.write(f"- âœ… PASS: {len(status_groups['PASS'])} ìƒ˜í”Œ\n")
        f.write(f"- âš ï¸ WARN: {len(status_groups['WARN'])} ìƒ˜í”Œ\n")
        f.write(f"- âŒ FAIL: {len(status_groups['FAIL'])} ìƒ˜í”Œ\n")
        f.write(f"- ğŸ”´ ERROR: {len(status_groups['ERROR'])} ìƒ˜í”Œ\n\n")
        
        f.write("=" * 80 + "\n\n")
        
        # FAIL ìƒ˜í”Œ (ì‹¬ê°í•œ ë¬¸ì œ)
        if status_groups['FAIL']:
            f.write("## âŒ FAIL - ì¦‰ì‹œ í™•ì¸ í•„ìš”\n\n")
            f.write("**ì‹¬ê°í•œ í’ˆì§ˆ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ì‹œí€€ì‹± ë˜ëŠ” ë¶„ì„ ì œì™¸ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.**\n\n")
            
            for result in sorted(status_groups['FAIL'], key=lambda x: x['sample']):
                f.write(f"### {result['sample']}\n\n")
                f.write(f"**ê¶Œì¥ì‚¬í•­**: {result['recommendation']}\n\n")
                
                if result['issues']:
                    f.write("**ë¬¸ì œì **:\n")
                    for issue in result['issues']:
                        f.write(f"- ğŸ”´ {issue}\n")
                    f.write("\n")
                
                if result['warnings']:
                    f.write("**ê²½ê³ **:\n")
                    for warning in result['warnings']:
                        f.write(f"- âš ï¸ {warning}\n")
                    f.write("\n")
                
                if 'basic_stats' in result:
                    f.write("**ê¸°ë³¸ í†µê³„**:\n")
                    f.write(f"- Total Sequences: {result['basic_stats'].get('Total Sequences', 'N/A')}\n")
                    f.write(f"- GC Content: {result['basic_stats'].get('%GC', 'N/A')}%\n")
                    f.write(f"- Sequence Length: {result['basic_stats'].get('Sequence length', 'N/A')}\n\n")
                
                f.write("-" * 80 + "\n\n")
        
        # WARN ìƒ˜í”Œ (ê²½ë¯¸í•œ ë¬¸ì œ)
        if status_groups['WARN']:
            f.write("## âš ï¸ WARN - ë¦¬í¬íŠ¸ í™•ì¸ ê¶Œì¥\n\n")
            f.write("**ê²½ë¯¸í•œ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. FastQC HTML ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.**\n\n")
            
            for result in sorted(status_groups['WARN'], key=lambda x: x['sample']):
                f.write(f"### {result['sample']}\n\n")
                
                if result['warnings']:
                    f.write("**ê²½ê³ **:\n")
                    for warning in result['warnings']:
                        f.write(f"- âš ï¸ {warning}\n")
                    f.write("\n")
                
                f.write("-" * 80 + "\n\n")
        
        # PASS ìƒ˜í”Œ (ì •ìƒ)
        if status_groups['PASS']:
            f.write("## âœ… PASS - ë¶„ì„ ì‚¬ìš© ê°€ëŠ¥\n\n")
            f.write("**í’ˆì§ˆ ê¸°ì¤€ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë¶„ì„ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.**\n\n")
            
            pass_samples = sorted([r['sample'] for r in status_groups['PASS']])
            for i in range(0, len(pass_samples), 5):
                f.write("- " + ", ".join(pass_samples[i:i+5]) + "\n")
            f.write("\n")
        
        # ERROR ìƒ˜í”Œ
        if status_groups['ERROR']:
            f.write("## ğŸ”´ ERROR - í‰ê°€ ì‹¤íŒ¨\n\n")
            for result in sorted(status_groups['ERROR'], key=lambda x: x['sample']):
                f.write(f"### {result['sample']}\n\n")
                f.write(f"**ì—ëŸ¬ ë©”ì‹œì§€**: {result.get('message', 'Unknown error')}\n\n")
                f.write("-" * 80 + "\n\n")
        
        # ì¶”ê°€ ì•ˆë‚´
        f.write("=" * 80 + "\n\n")
        f.write("## ğŸ“ ì°¸ê³ ì‚¬í•­\n\n")
        f.write("### RNA-seqì—ì„œ ì •ìƒì ì¸ FAIL íŒ¨í„´\n\n")
        f.write("ë‹¤ìŒ ëª¨ë“ˆë“¤ì€ RNA-seq ë°ì´í„°ì˜ íŠ¹ì„±ìƒ FAILì´ ë‚˜ì™€ë„ ì •ìƒì…ë‹ˆë‹¤:\n\n")
        f.write("- **Per base sequence content**: ëœë¤ í—¥ì‚¬ë¨¸ í”„ë¼ì´ë° í¸í–¥ (ì²˜ìŒ 10-15bp)\n")
        f.write("- **Sequence Duplication Levels**: ê³ ë°œí˜„ ìœ ì „ì (Actb, Gapdh, rRNA)\n")
        f.write("- **Overrepresented sequences**: rRNA, ë¯¸í† ì½˜ë“œë¦¬ì•„, í•˜ìš°ìŠ¤í‚¤í•‘ ìœ ì „ì\n")
        f.write("- **Adapter Content** (trimming ì „): Insert < Read length\n\n")
        
        f.write("### ë‹¤ìŒ ë‹¨ê³„\n\n")
        f.write("1. **FAIL ìƒ˜í”Œ**: FastQC HTML ë¦¬í¬íŠ¸ë¥¼ ì—´ì–´ ìƒì„¸ í™•ì¸\n")
        f.write("2. **WARN ìƒ˜í”Œ**: ê²½ê³  ë‚´ìš© ê²€í†  í›„ ì§„í–‰ ì—¬ë¶€ ê²°ì •\n")
        f.write("3. **PASS ìƒ˜í”Œ**: ë‹¤ìŒ ë¶„ì„ ë‹¨ê³„ ì§„í–‰\n\n")
        
        f.write("ìì„¸í•œ í•´ì„ ê°€ì´ë“œëŠ” `FASTQC_GUIDE.md`ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n\n")


def main():
    parser = argparse.ArgumentParser(
        description='FastQC ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ í‰ê°€í•˜ì—¬ í’ˆì§ˆ ë¬¸ì œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.'
    )
    parser.add_argument(
        'qc_dir',
        help='FastQC ê²°ê³¼ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ (ì˜ˆ: results/qc/)'
    )
    parser.add_argument(
        '-o', '--output',
        default='results/qc/fastqc_evaluation.txt',
        help='í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥ ê²½ë¡œ (ê¸°ë³¸ê°’: results/qc/fastqc_evaluation.txt)'
    )
    parser.add_argument(
        '--json',
        help='JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥í•  ê²½ë¡œ (ì„ íƒì‚¬í•­)'
    )
    parser.add_argument(
        '--config',
        help='QC ê¸°ì¤€ ì„¤ì • íŒŒì¼ (JSON, ì„ íƒì‚¬í•­)'
    )
    parser.add_argument(
        '--trimmed',
        action='store_true',
        help='Trimming í›„ ë°ì´í„° í‰ê°€ (ì–´ëŒ‘í„° í•¨ëŸ‰ ì—„ê²©íˆ ì²´í¬)'
    )
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = {
        'min_total_sequences': 1000000,
        'min_gc_content': 30,
        'max_gc_content': 70,
        'min_median_quality': 28,
        'min_lower_quartile': 20,
        'min_q30_percentage': 75,
        'max_n_content': 5.0,
        'critical_n_content': 10.0,
        'max_adapter_trimmed': 1.0,
        'warn_adapter_raw': 10.0
    }
    
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r') as f:
            custom_config = json.load(f)
            config.update(custom_config)
    
    # Evaluator ìƒì„±
    evaluator = FastQCEvaluator(config)
    
    # QC ë””ë ‰í† ë¦¬ì—ì„œ FastQC ê²°ê³¼ ì°¾ê¸°
    qc_dir = Path(args.qc_dir)
    if not qc_dir.exists():
        print(f"ERROR: QC directory not found: {qc_dir}", file=sys.stderr)
        sys.exit(1)
    
    # FastQC zip íŒŒì¼ ì°¾ê¸°
    fastqc_files = list(qc_dir.glob('*_fastqc.zip'))
    
    if not fastqc_files:
        print(f"ERROR: No FastQC results found in {qc_dir}", file=sys.stderr)
        sys.exit(1)
    
    print(f"Found {len(fastqc_files)} FastQC results")
    print(f"Evaluating with RNA-seq specific criteria...")
    print(f"Trimmed data: {args.trimmed}")
    print()
    
    # ê° ìƒ˜í”Œ í‰ê°€
    results = []
    for fastqc_zip in sorted(fastqc_files):
        sample_name = fastqc_zip.stem.replace('_fastqc', '')
        print(f"Evaluating: {sample_name}...", end=' ')
        
        result = evaluator.evaluate_sample(
            sample_name,
            str(fastqc_zip),
            is_trimmed=args.trimmed
        )
        results.append(result)
        
        # ìƒíƒœì— ë”°ë¼ ìƒ‰ìƒ ì¶œë ¥ (í„°ë¯¸ë„ ì§€ì›ì‹œ)
        status_symbol = {
            'PASS': 'âœ…',
            'WARN': 'âš ï¸',
            'FAIL': 'âŒ',
            'ERROR': 'ğŸ”´'
        }.get(result['status'], '?')
        
        print(f"{status_symbol} {result['status']}")
    
    print()
    print("=" * 80)
    print(f"Evaluation complete!")
    print(f"  PASS: {sum(1 for r in results if r['status'] == 'PASS')}")
    print(f"  WARN: {sum(1 for r in results if r['status'] == 'WARN')}")
    print(f"  FAIL: {sum(1 for r in results if r['status'] == 'FAIL')}")
    print(f"  ERROR: {sum(1 for r in results if r['status'] == 'ERROR')}")
    print("=" * 80)
    print()
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    generate_summary_report(results, args.output)
    print(f"Summary report saved to: {args.output}")
    
    # JSON ì €ì¥ (ì„ íƒì‚¬í•­)
    if args.json:
        with open(args.json, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"JSON results saved to: {args.json}")
    
    # FAILì´ ìˆìœ¼ë©´ exit code 1 ë°˜í™˜ (ì„ íƒì‚¬í•­ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥)
    # if any(r['status'] == 'FAIL' for r in results):
    #     sys.exit(1)
    
    sys.exit(0)


if __name__ == '__main__':
    main()
